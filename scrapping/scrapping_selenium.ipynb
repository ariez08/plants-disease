{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from urllib.parse import urljoin\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import hashlib\n",
    "import re\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, directory, filename):\n",
    "    if url.startswith(\"data:image\"):\n",
    "        # Handle embedded Base64-encoded images\n",
    "        header, encoded_data = url.split(\",\", 1)\n",
    "        image_extension = re.findall(r\"data:image/(\\w+);\", header)[0]\n",
    "        image_data = base64.b64decode(encoded_data)\n",
    "        file_path = os.path.join(directory, f\"{filename}.{image_extension}\")\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(image_data)\n",
    "    else:\n",
    "        # Handle regular image URLs\n",
    "        response = requests.get(url)\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_images(query, num_images, download_location):\n",
    "    query = query.replace(\" \", \"+\")\n",
    "    url = f\"https://www.google.com/search?q={query}&tbm=isch\"\n",
    "\n",
    "    os.makedirs(download_location, exist_ok=True)\n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "    chromedriver_path = \"./assets\\chromedriver_win32\\chromedriver.exe\"\n",
    "\n",
    "    service = Service(chromedriver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "    scroll_count = 0\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        scroll_count += 1\n",
    "\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CLASS_NAME, \"rg_i\")))\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        if scroll_count == 10:\n",
    "            break\n",
    "\n",
    "    image_elements = driver.find_elements(By.CLASS_NAME, \"rg_i\")\n",
    "\n",
    "    downloaded_images = 0\n",
    "    unique_images = set()\n",
    "\n",
    "    for i, image_element in enumerate(image_elements):\n",
    "        if image_element is None:\n",
    "            continue\n",
    "\n",
    "        image_url = image_element.get_attribute(\"src\")\n",
    "        if image_url is None:\n",
    "            continue\n",
    "\n",
    "        if image_url.startswith(\"/\"):\n",
    "            image_url = f\"https://www.google.com{image_url}\"\n",
    "\n",
    "        image_hash = hashlib.md5(image_url.encode()).hexdigest()\n",
    "        if image_hash in unique_images:\n",
    "            continue\n",
    "\n",
    "        unique_images.add(image_hash)\n",
    "\n",
    "        filename = f\"{query}_{downloaded_images}.jpg\"\n",
    "        download_image(image_url, download_location, filename)\n",
    "        print(f\"Downloaded image: {filename}\")\n",
    "\n",
    "        downloaded_images += 1\n",
    "        if downloaded_images == num_images:\n",
    "            break\n",
    "\n",
    "    print(\"Image scraping complete!\")\n",
    "\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded image: kucing+munchkin+lucu_0.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_1.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_2.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_3.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_4.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_5.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_6.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_7.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_8.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_9.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_10.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_11.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_12.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_13.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_14.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_15.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_16.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_17.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_18.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_19.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_20.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_21.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_22.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_23.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_24.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_25.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_26.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_27.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_28.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_29.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_30.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_31.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_32.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_33.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_34.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_35.jpg\n",
      "Downloaded image: kucing+munchkin+lucu_36.jpg\n",
      "Image scraping complete!\n"
     ]
    }
   ],
   "source": [
    "# Specify the download path and call the scrape_images function\n",
    "download_path = \"./file\"\n",
    "query = \"kucing munchkin lucu\"\n",
    "scrape_images(query, 40, download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
